{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import Common\n",
    "from music import Music\n",
    "from pyspark import *\n",
    "from pyspark.streaming import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local appName=myapp>\n",
      "2.4.5\n"
     ]
    }
   ],
   "source": [
    "## Do not run this multiple times\n",
    "common = Common()\n",
    "sc = common.get_spark_core()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think of it for a moment – 1 Qunitillion = 1 Million Billion! Can you imagine how many drives / CDs / Blue-ray DVDs would be required to store them? It is difficult to imagine this scale of data generation even as a data science professional. While this pace of data generation is very exciting,  it has created entirely new set of challenges and has forced us to find new ways to handle Big Huge data effectively.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Think of it for a moment – 1 Qunitillion = 1 Million Billion! Can you imagine how many drives / CDs / Blue-ray DVDs would be required to store them? It is difficult to imagine this scale of data generation even as a data science professional. While this pace of data generation is very exciting,  it has created entirely new set of challenges and has forced us to find new ways to handle Big Huge data effectively.',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('/home/ec2-user/data/blogtexts')\n",
    "print(rdd.first())\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = sc.parallelize(data)\n",
    "print(rdd.first())\n",
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map\n",
      "input rdd:  [0, 1, 2, 3, 4]\n",
      "output rdd:  [0, 2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "print ('Map')\n",
    "def multiply_by_two(x:int) -> int:\n",
    "    return x*2\n",
    "    \n",
    "data = range(0,100)\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(5))\n",
    "\n",
    "rdd = rdd.map(multiply_by_two)\n",
    "print ('output rdd: ', rdd.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter\n",
      "input rdd:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "output rdd:  [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "print ('Filter')\n",
    "def filter_by_even(x:int) -> int:\n",
    "    return x%2==0\n",
    "\n",
    "data = range(0,100)\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(10))\n",
    "\n",
    "rdd = rdd.filter(filter_by_even)\n",
    "print ('output rdd: ', rdd.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlatMap Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatMap in function\n",
      "input rdd:  [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
      "output rdd:  ['1', '2', '3', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "print ('FlatMap in function')\n",
    "def flatten(x):\n",
    "    return x[1].split(',')\n",
    "\n",
    "data = [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.flatMap(flatten)\n",
    "print ('output rdd: ', rdd.take(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatMap in lambda\n",
      "input rdd:  [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
      "output rdd:  ['1', '2', '3', '5', '6', '7']\n"
     ]
    }
   ],
   "source": [
    "print ('FlatMap in lambda')\n",
    "data = [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.flatMap(lambda x: (x[1].split(',')))\n",
    "print ('output rdd: ', rdd.take(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlatMapValues Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatMapValues in function\n",
      "input rdd:  [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
      "output rdd:  [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n"
     ]
    }
   ],
   "source": [
    "print ('FlatMapValues in function')\n",
    "def flatten(x):\n",
    "    return x.split(' ')\n",
    "\n",
    "data = [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.flatMapValues(flatten)\n",
    "print ('output rdd: ', rdd.take(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlatMapValues in lambda\n",
      "input rdd:  [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
      "output rdd:  [('A', '1'), ('A', '2'), ('A', '3'), ('B', '5'), ('B', '6'), ('B', '7')]\n"
     ]
    }
   ],
   "source": [
    "print ('FlatMapValues in lambda')\n",
    "data = [('A', '1,2,3'), ('B', '5,6,7'), ('C', '8,9,10')]\n",
    "rdd = sc.parallelize(data)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.flatMapValues(lambda x: x.split(','))\n",
    "print ('output rdd: ', rdd.take(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with files and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header:  acousticness,danceability,duration_ms,energy,song_title,artist\n",
      "first csv:  0.0102,0.833,204600,0.434,Mask Off,Future\n",
      "first class:  ('Future', <music.Music object at 0x7f6eac639410>)\n"
     ]
    }
   ],
   "source": [
    "file = '/home/ec2-user/data/spotify.csv'\n",
    "rdd = sc.textFile(file)\n",
    "\n",
    "header = rdd.first()\n",
    "print ('header: ', header)\n",
    "\n",
    "rdd = rdd.filter(lambda x: x != header)\n",
    "print ('first csv: ', rdd.first())\n",
    "\n",
    "rdd = rdd.map(lambda x: x.split(',')).map(lambda x: (x[5], Music(x[0], x[1], x[2], x[3], x[4], x[5])))\n",
    "print ('first class: ', rdd.first())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[acoustic: 0.0102] [dance: 0.833] [duration: 204600] [energy: 0.434] [title: Mask Off] [artist: Future]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_music(music:Music):\n",
    "        return ('[acoustic: ' + music.acoustic + '] ' +\n",
    "               '[dance: ' + music.dance + '] ' +\n",
    "               '[duration: ' + music.duration + '] ' +\n",
    "               '[energy: ' + music.energy + '] ' +\n",
    "               '[title: ' + music.title + '] ' +\n",
    "               '[artist: ' + music.artist+ ']')\n",
    "print_music(rdd.first()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReduceByKey Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped First:  ('Future', 1)\n",
      "Mapped Count:  2017\n",
      "\n",
      "Reduced First:  ('Future', 8)\n",
      "Reduced Count:  1369\n"
     ]
    }
   ],
   "source": [
    "rdd_mapped = rdd.map(lambda x: (x[0], 1))\n",
    "print ('Mapped First: ', rdd_mapped.first())\n",
    "print ('Mapped Count: ', rdd_mapped.count())\n",
    "\n",
    "# count occurrence of \"artist\"\n",
    "rdd_reduced = rdd_mapped.reduceByKey(lambda x,y: x+y)\n",
    "print ('\\nReduced First: ', rdd_reduced.first())\n",
    "print ('Reduced Count: ', rdd_reduced.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped First:  ('Future', 1)\n",
      "Mapped Count:  2017\n",
      "\n",
      "Grouped First:  ('Future', <pyspark.resultiterable.ResultIterable object at 0x7f6eabbd2c90>)\n",
      "Grouped Count:  1369\n",
      "\n",
      "Grouped first details:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1),\n",
       " ('Future', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_mapped = rdd.map(lambda x: (x[0], 1))\n",
    "print ('Mapped First: ', rdd_mapped.first())\n",
    "print ('Mapped Count: ', rdd_mapped.count())\n",
    "\n",
    "# count occurrence of \"artist\"\n",
    "rdd_grouped = rdd_mapped.groupBy(lambda w: w[0])\n",
    "print ('\\nGrouped First: ', rdd_grouped.first())\n",
    "print ('Grouped Count: ', rdd_grouped.count())\n",
    "\n",
    "print ('\\nGrouped first details:')\n",
    "list(rdd_grouped.first()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions and re-partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current partitions:  1\n",
      "Record count:  2017\n",
      "\n",
      "New partitions:  3\n",
      "Record count:  2017\n"
     ]
    }
   ],
   "source": [
    "print ('Current partitions: ', rdd.getNumPartitions())\n",
    "print ('Record count: ', rdd.count())\n",
    "\n",
    "rdd = rdd.repartition(3)\n",
    "print ('\\nNew partitions: ', rdd.getNumPartitions())\n",
    "print ('Record count: ', rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapPartition Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped First:  ('Cajmere', 1)\n",
      "Mapped Count:  2017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('Cajmere', 1),\n",
       "  ('The Rapture', 1),\n",
       "  ('Young Thug', 1),\n",
       "  ('Ty Segall', 1),\n",
       "  ('Myron & E', 1)],\n",
       " [('Future', 1),\n",
       "  ('Childish Gambino', 1),\n",
       "  ('Future', 1),\n",
       "  ('Beach House', 1),\n",
       "  ('Junior Boys', 1)],\n",
       " [('The Avalanches', 1),\n",
       "  ('Modern Folk', 1),\n",
       "  ('Erkin Koray', 1),\n",
       "  ('Lil Yachty', 1),\n",
       "  ('PNL', 1)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_mapped = rdd.map(lambda x: (x[0], 1))\n",
    "print ('Mapped First: ', rdd_mapped.first())\n",
    "print ('Mapped Count: ', rdd_mapped.count())\n",
    "\n",
    "def func(iterator):\n",
    "    yield list(iterator)[0:5]\n",
    "    \n",
    "rdd_mp = rdd_mapped.mapPartitions(func)\n",
    "rdd_mp.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [('brocoli', 6), ('melon', 3), ('banana', 1), ('melon', 4), ('brocoli', 9), ('melon', 15), ('brocoli', 16), ('melon', 13), ('banana', 11)]\n",
      "\n",
      "Label:  [('brocoli', 'veggie'), ('melon', 'fruit'), ('banana', 'fruit')]\n"
     ]
    }
   ],
   "source": [
    "data = [('brocoli', 6), ('melon', 3), ('banana', 1), ('melon', 4), ('brocoli', 9), ('melon', 15), ('brocoli', 16), ('melon', 13), ('banana', 11)]\n",
    "label = [('brocoli','veggie'), ('melon','fruit'), ('banana','fruit')]\n",
    "\n",
    "data_rdd = sc.parallelize(data)\n",
    "label_rdd = sc.parallelize(label)\n",
    "\n",
    "print ('Data: ', data_rdd.collect())\n",
    "print ('\\nLabel: ', label_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('melon', 'fruit', 3),\n",
       " ('melon', 'fruit', 4),\n",
       " ('melon', 'fruit', 15),\n",
       " ('melon', 'fruit', 13),\n",
       " ('banana', 'fruit', 1),\n",
       " ('banana', 'fruit', 11),\n",
       " ('brocoli', 'veggie', 6),\n",
       " ('brocoli', 'veggie', 9),\n",
       " ('brocoli', 'veggie', 16)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = data_rdd.join(label_rdd).map(lambda x: (x[0], x[1][1], x[1][0]))\n",
    "joined.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 'C', 'D']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"UNION\")\n",
    "rdd1 = sc.parallelize([1,2,3])\n",
    "rdd2 = sc.parallelize(['C', 'D'])\n",
    "rdd3 = rdd1.union(rdd2)\n",
    "rdd3.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.saveAsTextFile(\"/home/ec2-user/output/joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
